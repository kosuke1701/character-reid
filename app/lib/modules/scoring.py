import torch

def metric_l2(tensor1, tensor2):
    return - torch.norm(tensor1 - tensor2, dim=1)

class AbstractScoringModel(object):
    def compute_score(self, feature_set1, feature_set2, mode):
        raise NotImplementedError()

class VectorEmbeddingScoringModel(AbstractScoringModel):
    def __init__(self, sim_func, batch_size=100000):
        self.sim_func = sim_func
        self.bs = batch_size
    
    def compute_score(self, tensor1, tensor2, mode):
        if mode == "pair":
            d = tensor1.size(1)
            n1 = tensor1.size(0)
            n2 = tensor2.size(0)

            # Split larger tensor to reduce peak memory usage.
            n_chunk = n1 * n2 // self.bs
            if n1 >= n2:
                chunks = torch.chunk(tensor1, n_chunk, dim=0)
                sims = []
                for chunk in chunks:
                    _n1 = chunk.size(0)
                    sims.append(
                        self.sim_func(
                            chunk.repeat(1, n2).view(_n1*n2, d),
                            tensor2.repeat(_n1, 1)
                        ).view(_n1, n2)
                    )
                if len(sims) > 1:
                    sims = torch.cat(sims, dim=0)
                else:
                    sims = sims[0]
            else:
                chunks = torch.chunk(tensor2, n_chunk, dim=0)
                sims = []
                for chunk in chunks:
                    _n2 = chunk.size(0)
                    sims.append(
                        self.sim_func(
                            tensor1.repeat(1, _n2).view(n1*_n2, d),
                            chunk.repeat(n1, 1)
                        ).view(n1, _n2)
                    )
                if len(sims) > 1:
                    sims = torch.cat(sims, dim=1)
                else:
                    sims = sims[0]
            
            return sims

        elif mode == "batch":
            return self.sim_func(tensor1, tensor2)
        

